{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e38b2fd2-d8c6-4955-a087-2b5b3edaca0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI had a idea from work like below for my final projects, I think I will doing solo but if anyone want to work together you are more than welcome to DM me. \\n\\nBackground: My job is sale directors for steel companies, so we hitting the road really often, when we going out to visit customer, we will visit 3-4 customer at the same time. Everytime I need to find information like what is the sale volume to customer last month, what is the sizes, what is the average prices or previous month prices, I need to open my laptop, get to the ERP and found the information. \\n\\nMy project: I will made use a local LLMs and Perplexity as my personal assistance. So I will make RAG to access the database, take out the information I need, example like the list of sizes we sold to customers. The material description can be change but can be also repeating multiple times, the diffirences is in the volume wise.\\n\\n\\nInterface: I think I will use Gradio to do chat interface, then deploy to Hughing Face with address that only me can access \\n\\nExtra Credit: It is already a structured data to begin with hahaha. I am thinking about routing agents as tools call.\\nThere will be 3 tools calling:\\n1/Use PandasQueryEngines to get information of averages prices etc...\\n2/Use Tools to drawing a charts using data from PandasQuery Engines results\\n3/Using tools to passed the Queries to Perplexity when I asking something like where is the company, what information it hads. Meaning outside of the RAG Database and most up-to-date data. \\n\\nThe table will have 8 columns:\\nCustomer name, Item code, Description, Quantity, Unit, Price per unit, Total value, Billing date. \\n\\nThis 8 columns enough data for me. From customer name, if I want any other information, Perplexity can help me. \\n\\nI choose to reduce the complexity of the data in order to 1 single client data including a very few columns but having many many rows instead, this should fit to my need, no need to get a really complex multiple relationship database. \\n\\nFYI: The description will be in Vietnamese so Local LLM need to able to handle multi-language.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "I had a idea from work like below for my final projects, I think I will doing solo but if anyone want to work together you are more than welcome to DM me. \n",
    "\n",
    "Background: My job is sale directors for steel companies, so we hitting the road really often, when we going out to visit customer, we will visit 3-4 customer at the same time. Everytime I need to find information like what is the sale volume to customer last month, what is the sizes, what is the average prices or previous month prices, I need to open my laptop, get to the ERP and found the information. \n",
    "\n",
    "My project: I will made use a local LLMs and Perplexity as my personal assistance. So I will make RAG to access the database, take out the information I need, example like the list of sizes we sold to customers. The material description can be change but can be also repeating multiple times, the diffirences is in the volume wise.\n",
    "\n",
    "\n",
    "Interface: I think I will use Gradio to do chat interface, then deploy to Hughing Face with address that only me can access \n",
    "\n",
    "Extra Credit: It is already a structured data to begin with hahaha. I am thinking about routing agents as tools call.\n",
    "There will be 3 tools calling:\n",
    "1/Use PandasQueryEngines to get information of averages prices etc...\n",
    "2/Use Tools to drawing a charts using data from PandasQuery Engines results\n",
    "3/Using tools to passed the Queries to Perplexity when I asking something like where is the company, what information it hads. Meaning outside of the RAG Database and most up-to-date data. \n",
    "\n",
    "The table will have 8 columns:\n",
    "Customer name, Item code, Description, Quantity, Unit, Price per unit, Total value, Billing date. \n",
    "\n",
    "This 8 columns enough data for me. From customer name, if I want any other information, Perplexity can help me. \n",
    "\n",
    "I choose to reduce the complexity of the data in order to 1 single client data including a very few columns but having many many rows instead, this should fit to my need, no need to get a really complex multiple relationship database. \n",
    "\n",
    "FYI: The description will be in Vietnamese so Local LLM need to able to handle multi-language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89e9874-2c73-496e-bdec-abb49e05fabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install -q openai\\n!pip install -q sentence-transformers\\n!pip install -q llama-index-program-openai\\n!pip install -q llama-index-llms-openai\\n!pip install -q llama-index-experimental\\n!pip install -q llama-index-embeddings-huggingface\\n!pip install xlrd>=2.0.1\\n!ollama pull llama3.1\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install -q openai\n",
    "!pip install -q sentence-transformers\n",
    "!pip install -q llama-index-program-openai\n",
    "!pip install -q llama-index-llms-openai\n",
    "!pip install -q llama-index-experimental\n",
    "!pip install -q llama-index-embeddings-huggingface\n",
    "!pip install xlrd>=2.0.1\n",
    "!ollama pull llama3.1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e9226f-e16b-4f73-a5b3-69d4106368c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ollama\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "from llama_index.core import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d220e2-92e0-46d5-8729-83e5d249df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_keys():\n",
    "    \"\"\"\n",
    "    Loads API keys from a .env file and sets the OpenAI API key as an environment variable.\n",
    "\n",
    "    This function searches for a .env file in the current directory and its parent directories.\n",
    "    It then loads the environment variables from the found .env file.\n",
    "    Specifically, it retrieves the 'OPENAI_API_KEY' and 'HF_KEY' variables,\n",
    "    and sets the 'OPENAI_API_KEY' as an environment variable for the current process.\n",
    "\n",
    "    Example .env file:\n",
    "    ```\n",
    "    OPENAI_API_KEY=your_openai_api_key\n",
    "    HF_KEY=your_huggingface_api_key\n",
    "    ```\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If no .env file is found in the directory hierarchy.\n",
    "        KeyError: If either 'OPENAI_API_KEY' or 'HF_KEY' are not defined in the .env file.\n",
    "\n",
    "    Returns:\n",
    "        None. The function modifies the environment directly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dotenv_path = find_dotenv()  # Searches up the directory tree\n",
    "        if not dotenv_path:\n",
    "            raise FileNotFoundError(\"No .env file found in the directory hierarchy.\")\n",
    "\n",
    "        print(f\"Loading dotenv from: {dotenv_path}\")\n",
    "        load_dotenv(dotenv_path)\n",
    "\n",
    "        openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "        hf_key = os.getenv('HF_KEY')\n",
    "\n",
    "        if not openai_api_key:\n",
    "            raise KeyError(\"OPENAI_API_KEY not found in .env file.\")\n",
    "        if not hf_key:\n",
    "            raise KeyError(\"HF_KEY not found in .env file.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        raise\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9dad35-d696-42b3-b9bc-d34bbac99024",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e90273-af27-4ddc-a3d1-4637ea379262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "**I am an AI designed to simulate a helpful conversation. Here's more information about me:**\n",
      "\n",
      "* **Name:** My primary function is to provide general knowledge, but I don't have a specific \"name\" like a human would.\n",
      "* **Version:** I'm a large language model trained by Meta AI (previously known as Meta ai Model), and my version is not publicly disclosed due to the iterative updates and improvements made to my model over time. I'll refer to it as \"LLaMA-Model 1.0\" with the caveat that I'm an open-ended, continuously learning model.\n",
      "* **Parameter:** My size or capacity is measured in parameters (i.e., tens of billions). This includes attention mechanisms and transformer layers that power my ability to generate human-like text responses.\n",
      "\n",
      "**Strengths:** My capabilities include:\n",
      "\n",
      "1.  Answering questions on a wide range of topics\n",
      "2.  Generating text based on prompts, conversations, or ideas\n",
      "3.  Translating languages (including basic support for Vietnamese)\n",
      "4.  Providing creative writing, story completion, and summarization services\n",
      "\n",
      "**Vietnamese Language Support:** Yes, I can understand and respond in simple Vietnamese phrases and sentences. However, please note that:\n",
      "\n",
      "*   My proficiency is not native-like, but I'm designed to serve as a helpful assistant.\n",
      "*   If you need more advanced conversations or detailed responses, it's better to use a dedicated Vietnamese AI model.\n",
      "\n",
      "For example, if you ask me to write a simple message in Vietnamese, such as \"Xin chào,\" (Hello), I'll attempt to respond accordingly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nPrints the model's response to the console.\\n\\nThis line extracts the content of the model's response from the API's response object and prints it.\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "Ollama_MODEL = \"llama3.1\"  # Specifies the Ollama model to use.\n",
    "\n",
    "Ollama_LLM = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\"\"\"\n",
    "An OpenAI client configured to interact with a local Ollama server.\n",
    "\n",
    "This client is initialized with the base URL of the Ollama API and a dummy API key.\n",
    "Ollama does not require a real API key, so \"ollama\" is used as a placeholder.\n",
    "\"\"\"\n",
    "\n",
    "response = Ollama_LLM.chat.completions.create(\n",
    "    model=Ollama_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Who are you? What is your name, version and Parameter?  What is your strength? Do you support Vietnamese language\"}\n",
    "    ]\n",
    ")\n",
    "\"\"\"\n",
    "Sends a chat completion request to the Ollama server.\n",
    "\n",
    "This request queries the specified Ollama model about its identity, capabilities, and language support.\n",
    "The response contains the model's answer.\n",
    "\"\"\"\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\"\"\"\n",
    "Prints the model's response to the console.\n",
    "\n",
    "This line extracts the content of the model's response from the API's response object and prints it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be5fb3df-2323-47b9-a23a-29976385aa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Usage:\\nfolder_path = \"Sale_Data\"  # Replace with the actual path to your folder\\ndf = load_excel_files(folder_path)\\n\\n#Debug:\\nif df is not None:\\n    print(df.head())  # Print the first few rows of the combined DataFrame\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_excel_files(folder_path):\n",
    "    \"\"\"Loads multiple .xls files from a folder into a single pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        folder_path: The path to the folder containing the .xls files.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the combined data from all .xls files,\n",
    "        or None if no .xls files are found or an error occurs.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".xls\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                df = pd.read_excel(file_path)\n",
    "                all_data.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {filename}: {e}\")\n",
    "                # Handle the error appropriately (e.g., skip the file, raise an exception)\n",
    "                return None\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"No .xls files found in the specified folder.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "      combined_df = pd.concat(all_data, ignore_index=True)\n",
    "      return combined_df\n",
    "    except Exception as e:\n",
    "      print(f\"Error combining dataframes: {e}\")\n",
    "      return None\n",
    "\"\"\"\n",
    "# Usage:\n",
    "folder_path = \"Sale_Data\"  # Replace with the actual path to your folder\n",
    "df = load_excel_files(folder_path)\n",
    "\n",
    "#Debug:\n",
    "if df is not None:\n",
    "    print(df.head())  # Print the first few rows of the combined DataFrame\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6bba96c-d825-4710-90d5-040f61cdaaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Item_Code</th>\n",
       "      <th>Item_Details</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Value</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Billing Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Công Ty TNHH Một Thành Viên Quang Min</td>\n",
       "      <td>50000304.0</td>\n",
       "      <td>HR 2.3x250x4C</td>\n",
       "      <td>8470.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>116886000.0</td>\n",
       "      <td>VND</td>\n",
       "      <td>2019-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Công Ty TNHH Một Thành Viên Quang Min</td>\n",
       "      <td>50000304.0</td>\n",
       "      <td>HR 2.3x45x3C</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>15663000.0</td>\n",
       "      <td>VND</td>\n",
       "      <td>2019-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Công Ty TNHH Một Thành Viên Quang Min</td>\n",
       "      <td>50000363.0</td>\n",
       "      <td>HR 2.0x1114x3000x220T</td>\n",
       "      <td>11110.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>154429000.0</td>\n",
       "      <td>VND</td>\n",
       "      <td>2019-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Công Ty TNHH Một Thành Viên Quang Min</td>\n",
       "      <td>50000030.0</td>\n",
       "      <td>CRFH 1.5x170x5Coil</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>47040000.0</td>\n",
       "      <td>VND</td>\n",
       "      <td>2019-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Công Ty TNHH Một Thành Viên Quang Min</td>\n",
       "      <td>50000030.0</td>\n",
       "      <td>CRFH 1.5x193x5Coil</td>\n",
       "      <td>2304.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>33868800.0</td>\n",
       "      <td>VND</td>\n",
       "      <td>2019-02-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company_Name   Item_Code           Item_Details  \\\n",
       "0  Công Ty TNHH Một Thành Viên Quang Min  50000304.0          HR 2.3x250x4C   \n",
       "1  Công Ty TNHH Một Thành Viên Quang Min  50000304.0           HR 2.3x45x3C   \n",
       "2  Công Ty TNHH Một Thành Viên Quang Min  50000363.0  HR 2.0x1114x3000x220T   \n",
       "3  Công Ty TNHH Một Thành Viên Quang Min  50000030.0     CRFH 1.5x170x5Coil   \n",
       "4  Công Ty TNHH Một Thành Viên Quang Min  50000030.0     CRFH 1.5x193x5Coil   \n",
       "\n",
       "   Quantity Unit        Value Currency Billing Date  \n",
       "0    8470.0   KG  116886000.0      VND   2019-02-16  \n",
       "1    1135.0   KG   15663000.0      VND   2019-02-16  \n",
       "2   11110.0   KG  154429000.0      VND   2019-02-15  \n",
       "3    3200.0   KG   47040000.0      VND   2019-02-20  \n",
       "4    2304.0   KG   33868800.0      VND   2019-02-20  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize empty df and load Sale_Data\n",
    "df = load_excel_files(\"Sale_Data\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18b605a-1f33-4d29-a865-805cc7f084b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique payer names\n",
    "unique_payers = df['Company_Name'].unique()\n",
    "\n",
    "# Display the unique payer names\n",
    "#unique_payers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af74a602-6724-4045-8892-ca5d465dbe57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRetrieves the prompts used by the PandasQueryEngine.\\n\\nThis method returns a dictionary of prompts that are used to generate queries for the language model.\\nThese prompts define the structure and instructions for the language model.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query_engine = PandasQueryEngine(df=df, verbose=True)\n",
    "query_engine = PandasQueryEngine(df=df, llm=Ollama_LLM, verbose=True)\n",
    "\"\"\"\n",
    "Initializes a PandasQueryEngine to query a pandas DataFrame using a language model.\n",
    "\n",
    "This query engine allows you to ask questions about the data in the DataFrame using natural language.\n",
    "The `llm` argument specifies the language model to use for generating queries.\n",
    "The `verbose=True` argument enables detailed logging of the query execution process.\n",
    "\n",
    "Args:\n",
    "    df (pd.DataFrame): The pandas DataFrame to query.\n",
    "    llm (OpenAI): The language model to use for querying.\n",
    "    verbose (bool): Whether to enable verbose logging.\n",
    "\"\"\"\n",
    "\n",
    "prompts = query_engine.get_prompts()\n",
    "\"\"\"\n",
    "Retrieves the prompts used by the PandasQueryEngine.\n",
    "\n",
    "This method returns a dictionary of prompts that are used to generate queries for the language model.\n",
    "These prompts define the structure and instructions for the language model.\n",
    "\"\"\"\n",
    "#print(prompts[\"pandas_prompt\"].template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c23b561d-685f-41e9-95fd-90fb90b9e1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "The dataframe contains data about sale data. \n",
      "It have 8 columns: \n",
      "Company_Name is the full name of the buyer\n",
      "Item_Code is the ERP \n",
      "Item_Details is the item information including the thickness, width, length of the steel\n",
      "Quantity is the purchasing quantity, column Quantity and column Unit away come together\n",
      "Unit is the unit of purchasing quantity, column Quantity and column Unit away come together\n",
      "Value is the purchasing value, column Value and column Currency away come together\n",
      "Currency is the unit of purchasing value, column Value and column Currency away come together\n",
      "Billing Date is the date that issues the billing or invoice\t\t\t\t\t\n",
      "\n",
      "This is the result of `print(df.head())`: {df_str}\n",
      "\n",
      "Follow these instructions: {instruction_str}\n",
      "Query: {query_str}\n",
      "\n",
      "Return the answer from the dataframe with a natural language explanation of the answer.\n",
      "Expression: \n"
     ]
    }
   ],
   "source": [
    "new_prompt = PromptTemplate(\n",
    "    \"\"\"\\\n",
    "You are working with a pandas dataframe in Python.\n",
    "The name of the dataframe is `df`.\n",
    "The dataframe contains data about sale data. \n",
    "It have 8 columns: \n",
    "Company_Name is the full name of the buyer\n",
    "Item_Code is the ERP \n",
    "Item_Details is the item information including the thickness, width, length of the steel\n",
    "Quantity is the purchasing quantity, column Quantity and column Unit away come together\n",
    "Unit is the unit of purchasing quantity, column Quantity and column Unit away come together\n",
    "Value is the purchasing value, column Value and column Currency away come together\n",
    "Currency is the unit of purchasing value, column Value and column Currency away come together\n",
    "Billing Date is the date that issues the billing or invoice\t\t\t\t\t\n",
    "\n",
    "This is the result of `print(df.head())`: {df_str}\n",
    "\n",
    "Follow these instructions: {instruction_str}\n",
    "Query: {query_str}\n",
    "\n",
    "Return the answer from the dataframe with a natural language explanation of the answer.\n",
    "Expression: \"\"\"\n",
    ")\n",
    "\n",
    "query_engine.update_prompts({\"pandas_prompt\": new_prompt})\n",
    "prompts = query_engine.get_prompts()\n",
    "print(prompts[\"pandas_prompt\"].template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9821f031-143f-4c60-a379-aca10292c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace predict with create\n",
    "def _predict(prompt, **kwargs):\n",
    "    \"\"\"Helper function to make predict calls using the Ollama API.\"\"\"\n",
    "    global Ollama_MODEL  # Access the global variable\n",
    "    response = Ollama_LLM.chat.completions.create(\n",
    "        model=Ollama_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an pandas dataframe expert, user will gave you an query, you will respond with Python executable query code using Pandas. Follow user instruction step by step.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt.format(**kwargs)}\n",
    "        ]\n",
    "    )\n",
    "    #print(prompts[\"pandas_prompt\"].template)\n",
    "    #print(prompt.format(**kwargs))\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Monkey patch the predict method onto the Ollama_LLM object\n",
    "Ollama_LLM.predict = _predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b17da7c-252a-42d3-bac2-35bf35a07d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What item company like Công Ty TNHH BOSEUNG VINA bough?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f02607-3512-419f-8c6d-2a3354d26a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary classes from the llama_index package\n",
    "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader, Document\n",
    "\n",
    "# Read documents from the specified directory and load a specific document, \"report.pdf\".\n",
    "documents = [Document(text=payer_name) for payer_name in df['Company_Name'].unique()]\n",
    "\n",
    "# Create a VectorStoreIndex object from the documents. This will involve processing the documents\n",
    "# and creating a vector representation for each of them, suitable for semantic searching.\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# Convert the VectorStoreIndex object into a query engine. This query engine can be used to\n",
    "# perform semantic searches on the index, matching natural language queries to the most relevant\n",
    "# documents in the index.\n",
    "query_engine_name = index.as_query_engine()\n",
    "\n",
    "# Use the query engine to search for documents that are relevant to the query\n",
    "# from the indexed documents based on the semantic understanding of the query.\n",
    "response = query_engine_name.query(\"What is company asaba full name?\")\n",
    "\n",
    "# Print the response obtained from the query. This will display the result of the semantic search,\n",
    "# showing the information or documents that best match the query about the 2024 outlook.\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c40cd-29b5-4b7c-b29b-742f6d8b71eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_name(query):\n",
    "    response = Ollama_LLM.chat.completions.create(\n",
    "        model=Ollama_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Extract the company name from this query: '{query}'. Return only the company name.\"}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "get_company_name(\"What did company asaba buy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a3fccf-31fc-4a22-afe2-35f9624c468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_company_name(query_text, company, response):\n",
    "    \"\"\"\n",
    "    Replaces the company name in the query text with the provided response.\n",
    "\n",
    "    Args:\n",
    "        query_text: The original query text.\n",
    "        company: The company name to be replaced.\n",
    "        response: The replacement text for the company name.\n",
    "\n",
    "    Returns:\n",
    "        The updated query text with the company name replaced.\n",
    "    \"\"\"\n",
    "    updated_query = query_text.lower().replace(company.lower(), response)\n",
    "    return updated_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d591fde-d80a-473e-b6cd-a6d955f675fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_query_with_company_name(query_text):\n",
    "    \"\"\"\n",
    "    Updates a query with the full company name obtained from a search engine.\n",
    "\n",
    "    Args:\n",
    "        query_text (str): The original query text.\n",
    "        query_engine_name: An object with a 'query' method for searching.\n",
    "        get_company_name (function): A function to extract the company name from the query.\n",
    "        update_company_name (function): A function to update the query with the full company name.\n",
    "\n",
    "    Returns:\n",
    "        str: The updated query text.\n",
    "    \"\"\"\n",
    "    #print(f\"Original Query: {query_text}\")\n",
    "\n",
    "    company = get_company_name(query_text)\n",
    "    #print(f\"Extracted Company: {company}\")\n",
    "\n",
    "    response = query_engine_name.query(f\"What is the company:'{company}' full name?\")\n",
    "    #print(f\"Search Response: {response}\")\n",
    "\n",
    "    response_text = str(response)\n",
    "\n",
    "    updated_query = update_company_name(query_text, company, response_text)\n",
    "    #print(f\"Updated Query: {updated_query}\")\n",
    "\n",
    "    return updated_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ea58c-2dc9-4ce0-af4e-916a95f0ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text =\"What average price did asaba company bought in whole 2019 by each month?\"\n",
    "pd_response = query_engine.query(update_query_with_company_name(query_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f43428-d7b2-4850-95b1-d6b5d4e01e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dbd927-f2c4-4d09-9545-967aa7e5a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_pd_llm = Ollama_LLM.chat.completions.create(\n",
    "    model=\"deepseek-r1:8b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are excel at taking in the pandas output and pandas intruction to make charts\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is Panda output, choose the best graph and running the python code to print the graph{pd_response}\"}\n",
    "    ]\n",
    ")\n",
    "print(response_pd_llm.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8812f94a-2831-453a-8a24-fcbc9e3c7f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1f516-4b04-4041-b2d4-de31522e7759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574bbb3e-c96b-4afb-b18f-b13aeb9de34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77818e59-969a-4d9f-bb40-20ec584f5224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd43dc-fadf-44f6-bf64-d97404251858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
