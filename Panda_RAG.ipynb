{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e38b2fd2-d8c6-4955-a087-2b5b3edaca0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI had a idea from work like below for my final projects, I think I will doing solo but if anyone want to work together you are more than welcome to DM me. \\n\\nBackground: My job is sale directors for steel companies, so we hitting the road really often, when we going out to visit customer, we will visit 3-4 customer at the same time. Everytime I need to find information like what is the sale volume to customer last month, what is the sizes, what is the average prices or previous month prices, I need to open my laptop, get to the ERP and found the information. \\n\\nMy project: I will made use a local LLMs and Perplexity as my personal assistance. So I will make RAG to access the database, take out the information I need, example like the list of sizes we sold to customers. The material description can be change but can be also repeating multiple times, the diffirences is in the volume wise.\\n\\n\\nInterface: I think I will use Gradio to do chat interface, then deploy to Hughing Face with address that only me can access \\n\\nExtra Credit: It is already a structured data to begin with hahaha. I am thinking about routing agents as tools call.\\nThere will be 3 tools calling:\\n1/Use PandasQueryEngines to get information of averages prices etc...\\n2/Use Tools to drawing a charts using data from PandasQuery Engines results\\n3/Using tools to passed the Queries to Perplexity when I asking something like where is the company, what information it hads. Meaning outside of the RAG Database and most up-to-date data. \\n\\nThe table will have 8 columns:\\nCustomer name, Item code, Description, Quantity, Unit, Price per unit, Total value, Billing date. \\n\\nThis 8 columns enough data for me. From customer name, if I want any other information, Perplexity can help me. \\n\\nI choose to reduce the complexity of the data in order to 1 single client data including a very few columns but having many many rows instead, this should fit to my need, no need to get a really complex multiple relationship database. \\n\\nFYI: The description will be in Vietnamese so Local LLM need to able to handle multi-language.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "I had a idea from work like below for my final projects, I think I will doing solo but if anyone want to work together you are more than welcome to DM me. \n",
    "\n",
    "Background: My job is sale directors for steel companies, so we hitting the road really often, when we going out to visit customer, we will visit 3-4 customer at the same time. Everytime I need to find information like what is the sale volume to customer last month, what is the sizes, what is the average prices or previous month prices, I need to open my laptop, get to the ERP and found the information. \n",
    "\n",
    "My project: I will made use a local LLMs and Perplexity as my personal assistance. So I will make RAG to access the database, take out the information I need, example like the list of sizes we sold to customers. The material description can be change but can be also repeating multiple times, the diffirences is in the volume wise.\n",
    "\n",
    "\n",
    "Interface: I think I will use Gradio to do chat interface, then deploy to Hughing Face with address that only me can access \n",
    "\n",
    "Extra Credit: It is already a structured data to begin with hahaha. I am thinking about routing agents as tools call.\n",
    "There will be 3 tools calling:\n",
    "1/Use PandasQueryEngines to get information of averages prices etc...\n",
    "2/Use Tools to drawing a charts using data from PandasQuery Engines results\n",
    "3/Using tools to passed the Queries to Perplexity when I asking something like where is the company, what information it hads. Meaning outside of the RAG Database and most up-to-date data. \n",
    "\n",
    "The table will have 8 columns:\n",
    "Customer name, Item code, Description, Quantity, Unit, Price per unit, Total value, Billing date. \n",
    "\n",
    "This 8 columns enough data for me. From customer name, if I want any other information, Perplexity can help me. \n",
    "\n",
    "I choose to reduce the complexity of the data in order to 1 single client data including a very few columns but having many many rows instead, this should fit to my need, no need to get a really complex multiple relationship database. \n",
    "\n",
    "FYI: The description will be in Vietnamese so Local LLM need to able to handle multi-language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e89e9874-2c73-496e-bdec-abb49e05fabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install -q pandas\\n!pip install -q openai\\n!pip install -q sentence-transformers\\n!pip install -q llama-index-program-openai\\n!pip install -q llama-index-llms-openai\\n!pip install -q llama-index-experimental\\n!pip install -q llama-index-embeddings-huggingface\\n!pip install -q llama-index-embeddings-fastembed\\n!pip install -q fastembed\\n!pip install -q xlrd>=2.0.1\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install -q pandas\n",
    "!pip install -q openai\n",
    "!pip install -q sentence-transformers\n",
    "!pip install -q llama-index-program-openai\n",
    "!pip install -q llama-index-llms-openai\n",
    "!pip install -q llama-index-experimental\n",
    "!pip install -q llama-index-embeddings-huggingface\n",
    "!pip install -q llama-index-embeddings-fastembed\n",
    "!pip install -q fastembed\n",
    "!pip install -q xlrd>=2.0.1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e9226f-e16b-4f73-a5b3-69d4106368c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ollama\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "from llama_index.core import PromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d220e2-92e0-46d5-8729-83e5d249df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading all the API from .env file\n",
    "\"\"\"\n",
    "dotenv_path = find_dotenv()  # Searches up the directory tree\n",
    "#print(f\"Loading dotenv from: {dotenv_path}\")\n",
    "load_dotenv(dotenv_path)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "hf_key = os.getenv('HF_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e90273-af27-4ddc-a3d1-4637ea379262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresponse = Ollama_LLM.chat.completions.create(\\n    model=Ollama_MODEL,\\n    messages=[\\n        {\"role\": \"user\", \"content\": \"Who are you? What is your name, version and Parameter?  What is your strength? Do you support Vietnamese language\"}\\n    ]\\n)\\nprint(response.choices[0].message.content)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Setuping Ollama by install Ollama, \n",
    "Then ollama pull llama3.1\n",
    "\"\"\"\n",
    "\n",
    "Ollama_MODEL = \"llama3.1\"  # Specifies the Ollama model to use.\n",
    "Ollama_LLM = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\"\"\"\n",
    "response = Ollama_LLM.chat.completions.create(\n",
    "    model=Ollama_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Who are you? What is your name, version and Parameter?  What is your strength? Do you support Vietnamese language\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "740dfb2b-dd62-4f37-912f-2c33801d24d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "<think>\n",
      "I'm DeepSeek-R1-Lite-Preview, an AI assistant created exclusively by the Chinese Company DeepSeek. I'll do my best to help you.\n",
      "My strengths include providing detailed explanations on various topics, helping with research, and offering creative solutions. I also specialize in multi-language support, including English, Chinese, Vietnamese, and more. I'm here to help you with a wide range of tasks, from answering questions to aiding with storytelling. Let's get started!\n",
      "</think>\n",
      "\n",
      "I'm DeepSeek-R1-Lite-Preview, an AI assistant created exclusively by the Chinese Company DeepSeek. I'll do my best to help you.\n",
      "\n",
      "My strengths include providing detailed explanations on various topics, helping with research, and offering creative solutions. I also specialize in multi-language support, including English, Chinese, Vietnamese, and more. I'm here to help you with a wide range of tasks, from answering questions to aiding with storytelling. Let's get started!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Setuping Deepseek (from Ollama) by install Ollama\n",
    "Then ollama pull deepseek-r1:8b\n",
    "\"\"\"\n",
    "\n",
    "Deepseek_MODEL = \"deepseek-r1:8b\"  # Specifies the Ollama model to use.\n",
    "Deepseek_LLM = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "response = Deepseek_LLM.chat.completions.create(\n",
    "    model=Deepseek_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Who are you? What is your name, version and Parameter?  What is your strength? Do you support Vietnamese language\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be5fb3df-2323-47b9-a23a-29976385aa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Usage:\\nfolder_path = \"Sale_Data\"  # Replace with the actual path to your folder\\ndf = load_excel_files(folder_path)\\n\\n#Debug:\\nif df is not None:\\n    print(df.head())  # Print the first few rows of the combined DataFrame\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_excel_files(folder_path):\n",
    "    \"\"\"Loads multiple .xls files from a folder into a single pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        folder_path: The path to the folder containing the .xls files.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the combined data from all .xls files,\n",
    "        or None if no .xls files are found or an error occurs.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".xls\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                df = pd.read_excel(file_path)\n",
    "                all_data.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {filename}: {e}\")\n",
    "                # Handle the error appropriately (e.g., skip the file, raise an exception)\n",
    "                return None\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"No .xls files found in the specified folder.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "      combined_df = pd.concat(all_data, ignore_index=True)\n",
    "      return combined_df\n",
    "    except Exception as e:\n",
    "      print(f\"Error combining dataframes: {e}\")\n",
    "      return None\n",
    "\"\"\"\n",
    "# Usage:\n",
    "folder_path = \"Sale_Data\"  # Replace with the actual path to your folder\n",
    "df = load_excel_files(folder_path)\n",
    "\n",
    "#Debug:\n",
    "if df is not None:\n",
    "    print(df.head())  # Print the first few rows of the combined DataFrame\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6bba96c-d825-4710-90d5-040f61cdaaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Item_Code</th>\n",
       "      <th>Item_Details</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Value</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Billing Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Công Ty TNHH Một Thành Viên Quang Min</td>\n",
       "      <td>50000304.0</td>\n",
       "      <td>HR 2.3x250x4C</td>\n",
       "      <td>8470.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>116886000.0</td>\n",
       "      <td>VND</td>\n",
       "      <td>2019-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Công Ty TNHH Một Thành Viên Quang Min</td>\n",
       "      <td>50000304.0</td>\n",
       "      <td>HR 2.3x45x3C</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>15663000.0</td>\n",
       "      <td>VND</td>\n",
       "      <td>2019-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Công Ty TNHH Một Thành Viên Quang Min</td>\n",
       "      <td>50000363.0</td>\n",
       "      <td>HR 2.0x1114x3000x220T</td>\n",
       "      <td>11110.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>154429000.0</td>\n",
       "      <td>VND</td>\n",
       "      <td>2019-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Công Ty TNHH Một Thành Viên Quang Min</td>\n",
       "      <td>50000030.0</td>\n",
       "      <td>CRFH 1.5x170x5Coil</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>47040000.0</td>\n",
       "      <td>VND</td>\n",
       "      <td>2019-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Công Ty TNHH Một Thành Viên Quang Min</td>\n",
       "      <td>50000030.0</td>\n",
       "      <td>CRFH 1.5x193x5Coil</td>\n",
       "      <td>2304.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>33868800.0</td>\n",
       "      <td>VND</td>\n",
       "      <td>2019-02-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company_Name   Item_Code           Item_Details  \\\n",
       "0  Công Ty TNHH Một Thành Viên Quang Min  50000304.0          HR 2.3x250x4C   \n",
       "1  Công Ty TNHH Một Thành Viên Quang Min  50000304.0           HR 2.3x45x3C   \n",
       "2  Công Ty TNHH Một Thành Viên Quang Min  50000363.0  HR 2.0x1114x3000x220T   \n",
       "3  Công Ty TNHH Một Thành Viên Quang Min  50000030.0     CRFH 1.5x170x5Coil   \n",
       "4  Công Ty TNHH Một Thành Viên Quang Min  50000030.0     CRFH 1.5x193x5Coil   \n",
       "\n",
       "   Quantity Unit        Value Currency Billing Date  \n",
       "0    8470.0   KG  116886000.0      VND   2019-02-16  \n",
       "1    1135.0   KG   15663000.0      VND   2019-02-16  \n",
       "2   11110.0   KG  154429000.0      VND   2019-02-15  \n",
       "3    3200.0   KG   47040000.0      VND   2019-02-20  \n",
       "4    2304.0   KG   33868800.0      VND   2019-02-20  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize empty df and load Sale_Data\n",
    "df = load_excel_files(\"Sale_Data\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b605a-1f33-4d29-a865-805cc7f084b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique payer names\n",
    "unique_payers = df['Company_Name'].unique()\n",
    "\n",
    "# Display the unique payer names\n",
    "#unique_payers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74a602-6724-4045-8892-ca5d465dbe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_engine = PandasQueryEngine(df=df, verbose=True) #OpenAI\n",
    "query_engine = PandasQueryEngine(df=df, llm=Deepseek_LLM, verbose=True)\n",
    "#query_engine = PandasQueryEngine(df=df, llm=Ollama_LLM, verbose=True)\n",
    "\"\"\"\n",
    "Initializes a PandasQueryEngine to query a pandas DataFrame using a language model.\n",
    "\n",
    "This query engine allows you to ask questions about the data in the DataFrame using natural language.\n",
    "The `llm` argument specifies the language model to use for generating queries.\n",
    "The `verbose=True` argument enables detailed logging of the query execution process.\n",
    "\"\"\"\n",
    "prompts = query_engine.get_prompts()\n",
    "#print(prompts[\"pandas_prompt\"].template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b561d-685f-41e9-95fd-90fb90b9e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = PromptTemplate(\n",
    "    \"\"\"\\\n",
    "You are working with a pandas dataframe in Python.\n",
    "The name of the dataframe is `df`.\n",
    "The dataframe contains data about sale data. \n",
    "It have 8 columns: \n",
    "Company_Name is the full name of the buyer\n",
    "Item_Code is the ERP \n",
    "Item_Details is the item information including the thickness, width, length of the steel\n",
    "Quantity is the purchasing quantity,\n",
    "Unit is the unit of purchasing quantity,\n",
    "Value is the purchasing value, \n",
    "Currency is the unit of purchasing value, \n",
    "Billing Date is the date that issues the billing or invoice\t\t\t\t\t\n",
    "\n",
    "This is the result of `print(df.head())`: {df_str}\n",
    "\n",
    "Follow these instructions: {instruction_str}\n",
    "Query: {query_str}\n",
    "\n",
    "Return the answer from the dataframe with a natural language explanation of the answer.\n",
    "\"Generate *only* Pandas code to answer the question. Do not include any surrounding text or keywords, such as 'python'.\"\n",
    "Expression: \"\"\"\n",
    ")\n",
    "\n",
    "query_engine.update_prompts({\"pandas_prompt\": new_prompt})\n",
    "prompts = query_engine.get_prompts()\n",
    "#print(prompts[\"pandas_prompt\"].template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821f031-143f-4c60-a379-aca10292c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace predict with create\n",
    "def _predict(prompt, **kwargs):\n",
    "    \"\"\"Helper function to make predict calls using the Ollama API.\"\"\"\n",
    "    global Ollama_MODEL  # Access the global variable\n",
    "    response = Ollama_LLM.chat.completions.create(\n",
    "        model=Ollama_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an pandas dataframe expert, user will gave you an query, you will respond with Python executable query code using Pandas. Follow user instruction step by step.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt.format(**kwargs)}\n",
    "        ]\n",
    "    )\n",
    "    #print(prompts[\"pandas_prompt\"].template)\n",
    "    #print(prompt.format(**kwargs))\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Monkey patch the predict method onto the Ollama_LLM object\n",
    "Ollama_LLM.predict = _predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccfb404-ded3-4af1-907c-97bad310ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace predict with create\n",
    "def _predict(prompt, **kwargs):\n",
    "    \"\"\"Helper function to make predict calls using the Ollama API.\"\"\"\n",
    "    global Deepseek_MODEL  # Access the global variable\n",
    "    response = Deepseek_LLM.chat.completions.create(\n",
    "        model=Deepseek_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an pandas dataframe expert, user will gave you an query, you will respond with Python executable query code using Pandas. Follow user instruction step by step.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt.format(**kwargs)}\n",
    "        ]\n",
    "    )\n",
    "    #print(prompts[\"pandas_prompt\"].template)\n",
    "    #print(prompt.format(**kwargs))\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Monkey patch the predict method onto the Ollama_LLM object\n",
    "Deepseek_LLM.predict = _predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b17da7c-252a-42d3-bac2-35bf35a07d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresponse = query_engine.query(\"What item details, quantiy and value did CÔNG TY TNHH ASABA VIET NAM MANUFACTURING company bought?\")\\nprint(str(response))\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "response = query_engine.query(\"What item details, quantiy and value did CÔNG TY TNHH ASABA VIET NAM MANUFACTURING company bought?\")\n",
    "print(str(response))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11e5133f-9cc2-428d-84c3-9be44f9545e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPandas_intrusction = response.metadata['pandas_instruction_str']\\nPandas_output = response.metadata['raw_pandas_output']\\nprint(Pandas_intrusction)\\nprint(Pandas_output)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Pandas_intrusction = response.metadata['pandas_instruction_str']\n",
    "Pandas_output = response.metadata['raw_pandas_output']\n",
    "print(Pandas_intrusction)\n",
    "print(Pandas_output)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "834d195e-987f-42da-8442-45216b51700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Since Local LLM is not smart, so I made a loop to running LLM multiple times with same prompts\n",
    "until it got the answer.\n",
    "\"\"\"\n",
    "\n",
    "def check_Query_output(prompt):\n",
    "    Error_check = False\n",
    "    Pandas_output = None  # Initialize Pandas_output\n",
    "\n",
    "    while not Error_check:  # Corrected while loop condition\n",
    "        Query_Answer = query_engine.query(prompt)\n",
    "        print(Query_Answer)\n",
    "        if Query_Answer.metadata and 'raw_pandas_output' in Query_Answer.metadata:\n",
    "            Pandas_intrusction = Query_Answer.metadata['pandas_instruction_str']\n",
    "            Pandas_output = Query_Answer.metadata['raw_pandas_output']\n",
    "            #print(Pandas_output)\n",
    "            if \"error\" in Pandas_output.lower():\n",
    "                prompt = prompt + \" \" + Pandas_output + \" \" + Pandas_intrusction\n",
    "                Error_check = False\n",
    "            else:\n",
    "                Error_check = True\n",
    "        else:\n",
    "            Pandas_output = str(Query_Answer)  # Return the string of the query answer.\n",
    "            Error_check = True # exit the loop.\n",
    "\n",
    "    return Pandas_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a82d643-5051-4bbd-8a2a-b40b5ea4b8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noutput = check_Query_output(\"What item details, quantiy and value did CÔNG TY TNHH ASABA VIET NAM MANUFACTURING company bought?\")\\nprint(output)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "output = check_Query_output(\"What item details, quantiy and value did CÔNG TY TNHH ASABA VIET NAM MANUFACTURING company bought?\")\n",
    "print(output)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f02607-3512-419f-8c6d-2a3354d26a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "from llama_index.core import StorageContext,load_index_from_storage\n",
    "\n",
    "# Import necessary classes from the llama_index package\n",
    "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader, Document\n",
    "\n",
    "# Read documents from the specified directory and load a specific document, \"report.pdf\".\n",
    "documents = [Document(text=payer_name) for payer_name in df['Company_Name'].unique()]\n",
    "\n",
    "# Create a VectorStoreIndex object from the documents. This will involve processing the documents\n",
    "# and creating a vector representation for each of them, suitable for semantic searching.\n",
    "embeddings = FastEmbedEmbedding()\n",
    "index = VectorStoreIndex.from_documents(documents, embeddings=embeddings)\n",
    "                                    \n",
    "# Create a storage context\n",
    "storage_context = StorageContext.from_defaults(vector_store=index.vector_store)\n",
    "\n",
    "# Persist the storage context to disk\n",
    "storage_context.persist()\n",
    "\n",
    "# Convert the VectorStoreIndex object into a query engine. This query engine can be used to\n",
    "# perform semantic searches on the index, matching natural language queries to the most relevant\n",
    "# documents in the index.\n",
    "query_engine_name = index.as_query_engine()\n",
    "\n",
    "# Use the query engine to search for documents that are relevant to the query\n",
    "# from the indexed documents based on the semantic understanding of the query.\n",
    "#response = query_engine_name.query(\"What is company asaba full name?\")\n",
    "\n",
    "# Print the response obtained from the query. This will display the result of the semantic search,\n",
    "# showing the information or documents that best match the query about the 2024 outlook.\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c40cd-29b5-4b7c-b29b-742f6d8b71eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_name(query):\n",
    "    response = Ollama_LLM.chat.completions.create(\n",
    "        model=Ollama_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Extract the company name from this query: '{query}'. Return only the company name.\"}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "#get_company_name(\"What did company asaba buy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a3fccf-31fc-4a22-afe2-35f9624c468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_company_name(query_text, company, response):\n",
    "\n",
    "    updated_query = query_text.lower().replace(company.lower(), response)\n",
    "    return updated_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d591fde-d80a-473e-b6cd-a6d955f675fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_query_with_company_name(query_text):\n",
    "\n",
    "    #print(f\"Original Query: {query_text}\")\n",
    "\n",
    "    company = get_company_name(query_text)\n",
    "    #print(f\"Extracted Company: {company}\")\n",
    "\n",
    "    response = query_engine_name.query(f\"What is the company:'{company}' full name?\")\n",
    "    #print(f\"Search Response: {response}\")\n",
    "\n",
    "    response_text = str(response)\n",
    "\n",
    "    updated_query = update_company_name(query_text, company, response_text)\n",
    "    #print(f\"Updated Query: {updated_query}\")\n",
    "\n",
    "    return updated_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea2dd6-9ee3-4fb1-a918-9cd6b5c47715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query_text):\n",
    "    updated_query = update_query_with_company_name(query_text)\n",
    "    result = check_Query_output(updated_query)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949592d-5d6f-4341-b5ad-82ce53c12ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.484374 seconds\n",
      "Retrying request to /chat/completions in 0.484374 seconds\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "<think>\n",
      "Okay, so the user is asking about the item details, quantity, and value that a specific company bought. The company name given is \"CÔNG TY TNHH ASABA VIET NAM MANUFACTURING.\" I need to help them write a Pandas query to extract this information from their dataframe.\n",
      "\n",
      "First, I know that in Pandas, filtering data based on column values is done using boolean indexing. So the first step is to filter the dataframe to only include rows where Company_Name matches the provided company name.\n",
      "\n",
      "Looking at the sample data, theCompany column has \"CÔNG Ty TNHH Một Thành Viên Quang Min\" as repeated entries. I notice that capitalization might differ, so I should make sure the comparison is case-insensitive, maybe by converting both to lowercase or uppercase.\n",
      "\n",
      "Once I have the filtered dataframe, I need to extract three columns: Item_Details, Quantity, and Value. So for each of those, I'll use df['Item_Details'], df['Quantity'], and df['Value'].\n",
      "\n",
      "Putting it all together, the code should first filter the dataframe and then select the required columns. To make this an expression that can be used with eval(), I should encapsulate everything in parentheses, ensuring the syntax is correct for evaluating within the function.\n",
      "\n",
      "I also need to ensure that variable names match correctly, like referring to the dataframe as 'df'. Since the user provided an example where print(df.head()) is called, I can assume df is already defined and accessible.\n",
      "\n",
      "So the final expression would look something like (df[df['Company_Name'] == 'CÔNG Ty TNHH ASABA VIET NAM MANUFACTURING.'][\"Item_Details\",\"Quantity\",\"Value\"]). This can be evaluated using eval(), but perhaps wrapping it in parentheses makes it clear for evaluation purposes.\n",
      "</think>\n",
      "\n",
      "(\"Item_Details Quantity Value that The company's full name is \\\"CÔNG TY TNHH ASABA VIET NAM MANUFACTURING.\\\" bought\")\n",
      "\n",
      "Pandas code to answer the query:\n",
      "\n",
      "(df[df['Company_Name'] == \"CÔNG Ty TNHH ASABA VIET NAM MANUFACTURING\"]['Item_Details','Quantity','Value'])\n",
      "\n",
      "This code filters the dataframe for rows where Company_Name matches \"CÔNG Ty TNHH ASABA VIET NAM MANUFACTURING\" and then selects the specified columns.\n",
      "```\n",
      "> Pandas Output: There was an error running the output as Python code. Error message: unterminated string literal (detected at line 8) (<unknown>, line 8)\n",
      "There was an error running the output as Python code. Error message: unterminated string literal (detected at line 8) (<unknown>, line 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\site-packages\\llama_index\\experimental\\query_engine\\pandas\\output_parser.py\", line 42, in default_output_processor\n",
      "    tree = ast.parse(output)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<unknown>\", line 8\n",
      "    Once I have the filtered dataframe, I need to extract three columns: Item_Details, Quantity, and Value. So for each of those, I'll use df['Item_Details'], df['Quantity'], and df['Value'].\n",
      "                                                                                                                                                                                            ^\n",
      "SyntaxError: unterminated string literal (detected at line 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "\n",
      "\n",
      "The final answer in executable Python code using Pandas:\n",
      "\n",
      "```python\n",
      "(df[df['Company_Name'] == \"CÔNG Ty TNHH ASABA VIET NAM MANUFACTURING\"]['Item_Details','Quantity','Value'])\n",
      "```\n",
      "```\n",
      "> Pandas Output: There was an error running the output as Python code. Error message: name 'python' is not defined\n",
      "There was an error running the output as Python code. Error message: name 'python' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\site-packages\\llama_index\\experimental\\query_engine\\pandas\\output_parser.py\", line 44, in default_output_processor\n",
      "    safe_exec(ast.unparse(module), {}, local_vars)  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\site-packages\\llama_index\\experimental\\exec_utils.py\", line 171, in safe_exec\n",
      "    return exec(__source, _get_restricted_globals(__globals), __locals)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 1, in <module>\n",
      "NameError: name 'python' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "\n",
      "\n",
      "To address this specific question, I will provide you with a tailored pandas query that extracts the required information.\n",
      "\n",
      "1. Filter the dataframe based on \"Company_Name\".\n",
      "2. Select the \"Item_Details\", \"Quantity\", and \"Value\" columns.\n",
      "\n",
      "The final expression is:\n",
      "\n",
      "expression = (\n",
      "    df[df['Company_Name'] == 'CÔNG Ty TNHH ASABA VIET NAM MANUFACTURING']\n",
      "       .loc[:, ['Item_Details', 'Quantity', 'Value']]\n",
      ")\n",
      "\n",
      "This can be evaluated using:\n",
      "\n",
      "eval(expression)\n",
      "\n",
      "The error occurred because the code was not properly enclosed in parentheses when used with eval(). The corrected expression is provided below.\n",
      "```\n",
      "> Pandas Output: There was an error running the output as Python code. Error message: invalid syntax (<unknown>, line 1)\n",
      "There was an error running the output as Python code. Error message: invalid syntax (<unknown>, line 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\site-packages\\llama_index\\experimental\\query_engine\\pandas\\output_parser.py\", line 42, in default_output_processor\n",
      "    tree = ast.parse(output)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<unknown>\", line 1\n",
      "    To address this specific question, I will provide you with a tailored pandas query that extracts the required information.\n",
      "       ^^^^^^^\n",
      "SyntaxError: invalid syntax\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "\n",
      "\n",
      "To find out which products were purchased by \"CÔNG Ty TNHH ASABA VIET NAM MANUFACTURING,\" we filter the dataframe based on `Company_Name` and select the relevant columns.\n",
      "\n",
      "**Expression:**\n",
      "```python\n",
      "(df[df['Company_Name'] == 'CÔNG Ty TNHH ASABA VIET NAM MANUFACTURING']['Item_Details','Quantity','Value'])\n",
      "```\n",
      "\n",
      "This expression filters rows where `Company_Name` matches \"CÔNG Ty TNHH ASABA VIET NAM MANUFACTURING\" and selects the specified columns from those rows.\n",
      "```\n",
      "> Pandas Output: There was an error running the output as Python code. Error message: name 'python' is not defined\n",
      "There was an error running the output as Python code. Error message: name 'python' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\site-packages\\llama_index\\experimental\\query_engine\\pandas\\output_parser.py\", line 44, in default_output_processor\n",
      "    safe_exec(ast.unparse(module), {}, local_vars)  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\site-packages\\llama_index\\experimental\\exec_utils.py\", line 171, in safe_exec\n",
      "    return exec(__source, _get_restricted_globals(__globals), __locals)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 1, in <module>\n",
      "NameError: name 'python' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "The final expression that can be used with `eval()` is:\n",
      "\n",
      "(\n",
      "    df[df['Company_Name'] == 'CÔNG Ty TNHH ASABA VIET NAM MANUFACTURING']\n",
      "    .loc[:, 'Item_Details', 'Quantity', 'Value']\n",
      ")\n",
      "```\n",
      "> Pandas Output: There was an error running the output as Python code. Error message: invalid syntax (<unknown>, line 1)\n",
      "There was an error running the output as Python code. Error message: invalid syntax (<unknown>, line 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\site-packages\\llama_index\\experimental\\query_engine\\pandas\\output_parser.py\", line 42, in default_output_processor\n",
      "    tree = ast.parse(output)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<unknown>\", line 1\n",
      "    **Answer:**\n",
      "    ^^\n",
      "SyntaxError: invalid syntax\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "\n",
      "\n",
      "The correct expression to use in Python for evaluating is:\n",
      "\n",
      "(\n",
      "    df[df['Company_Name'] == 'CÔNG Ty TNHH ASABA VIET NAM MANUFACTURING']\n",
      "       .loc[:, ['Item_Details', 'Quantity', 'Value']]\n",
      ")\n",
      "\n",
      "This expression can be evaluated using eval().\n",
      "```\n",
      "> Pandas Output: There was an error running the output as Python code. Error message: invalid syntax (<unknown>, line 1)\n",
      "There was an error running the output as Python code. Error message: invalid syntax (<unknown>, line 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\site-packages\\llama_index\\experimental\\query_engine\\pandas\\output_parser.py\", line 42, in default_output_processor\n",
      "    tree = ast.parse(output)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<unknown>\", line 1\n",
      "    The correct expression to use in Python for evaluating is:\n",
      "        ^^^^^^^\n",
      "SyntaxError: invalid syntax\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "\n",
      "\n",
      "The final expression is:\n",
      "\n",
      "(\n",
      "    df[df['Company_Name'] == \"CÔNG Ty TNHH ASABA VIET NAM MANUFACTURING\"]\n",
      "       .loc[:, ['Item_Details', 'Quantity', 'Value']]\n",
      ")\n",
      "\n",
      "This code will:\n",
      "1. Filter the dataframe for rows where Company_Name matches \"CÔNG Ty TNHH ASABA VIET NAM MANUFACTURING\"\n",
      "2. Select the Item_Details, Quantity, and Value columns.\n",
      "3. Return a DataFrame containing this information.\n",
      "\n",
      "The expression can be evaluated using eval():\n",
      "\n",
      "eval(\"(\n",
      "    df[df['Company_Name'] == 'CÔNG Ty TNHH ASABA VIET NAM MANUFACTURING']\n",
      "       .loc[:, ['Item_Details', 'Quantity', 'Value']]\n",
      ")\")\n",
      "\n",
      "This returns a DataFrame with the specified details for the matching company.\n",
      "```\n",
      "> Pandas Output: There was an error running the output as Python code. Error message: unterminated string literal (detected at line 15) (<unknown>, line 15)\n",
      "There was an error running the output as Python code. Error message: unterminated string literal (detected at line 15) (<unknown>, line 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\site-packages\\llama_index\\experimental\\query_engine\\pandas\\output_parser.py\", line 42, in default_output_processor\n",
      "    tree = ast.parse(output)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\jupyter-ai\\Lib\\ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<unknown>\", line 15\n",
      "    eval(\"(\n",
      "         ^\n",
      "SyntaxError: unterminated string literal (detected at line 15)\n"
     ]
    }
   ],
   "source": [
    "process_query(\"What item details, quantiy and value did asaba company bought?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec16d0b8-3638-46f2-a307-8db30789acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "iface = gr.ChatInterface(\n",
    "    fn=process_query,\n",
    "    chatbot=gr.Chatbot(height=300),\n",
    "    textbox=gr.Textbox(placeholder=\"Enter your query here...\"),\n",
    "    title=\"Pandas Query Chat with Memory\",\n",
    "    description=\"Enter a query to interact with your pandas DataFrame. The chat remembers your conversation.\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8812f94a-2831-453a-8a24-fcbc9e3c7f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1f516-4b04-4041-b2d4-de31522e7759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574bbb3e-c96b-4afb-b18f-b13aeb9de34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77818e59-969a-4d9f-bb40-20ec584f5224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd43dc-fadf-44f6-bf64-d97404251858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
